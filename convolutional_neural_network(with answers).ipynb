{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second session: multilayer perceptron MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-69c65344baec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder :The MNIST dataset is a set of greyscale images with 28*28=784 pixels.\n",
    "Each image is a number between 0 and 9.\n",
    "The goal of the practical is to obtain a classifier that can correctly \n",
    "classify the images into the 10 classes.\n",
    "The MNIST data consists of 55000 train images and labels, 5000 observations\n",
    "validation set and 10000 observations in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "x = tf.placeholder(tf.float32, [None, 784])#input\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])#labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP2 2: Deep Learning\n",
    "for more information about convolutional network : http://cs231n.github.io/convolutional-networks/#conv\n",
    "\n",
    "or a youtube video ;) : https://www.youtube.com/watch?v=bEUX_56Lojc\n",
    "\n",
    "The purpose: Getting 91% accuracy on MNIST is bad. It's almost embarrassingly bad. In \n",
    "this practical, we'll fix that, jumping from a very simple model to something\n",
    "moderately sophisticated: a small convolutional neural network. This will get \n",
    "us to around 99.2% accuracy -- not state of the art, but respectable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Initialization\n",
    "\n",
    "To create this model, we're going to need to create a lot of weights and \n",
    "biases. One should generally initialize weights with a small amount of \n",
    "noise for symmetry breaking, and to prevent 0 gradients. Since we're using \n",
    "ReLU neurons, it is also good practice to initialize them with a slightly \n",
    "positive initial bias to avoid \"dead neurons.\" Instead of doing this \n",
    "repeatedly while we build the model, let's create two handy functions to \n",
    "do it for us.\n",
    "\n",
    "#### Q1 : Why is symmetry breaking important ? What is a ReLU neuron and why is \"dead neurons\" a specific problem ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Pooling\n",
    "\n",
    "TensorFlow also gives us a lot of flexibility in convolution and pooling\n",
    " operations. How do we handle the boundaries? What is our stride size? Here\n",
    "we will use the simplest possible options. Our convolutions uses a stride \n",
    "of one and are zero padded so that the output is the same size as the input.\n",
    "Our pooling is max pooling over 2x2 blocks. To keep our code cleaner, let's\n",
    "also abstract those operations into functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First Convolutional Layer\n",
    "\n",
    "We can now implement our first layer. It will consist of convolution, \n",
    "followed by max pooling. The convolutional will compute 32 features for \n",
    "each 5x5 patch. Its weight tensor will have a shape of [5, 5, 1, 32]. The \n",
    "first two dimensions are the patch size, the next is the number of input \n",
    "channels, and the last is the number of output channels. We will also have\n",
    " a bias vector with a component for each output channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the layer, we first reshape x to a 4d tensor, with the second \n",
    "and third dimensions corresponding to image width and height, and the final\n",
    " dimension corresponding to the number of color channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1,28,28,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.1: What does the -1 in the shape vector mean? Use the documentation. Why do we need to reshape x compared to our first algorithm ?\n",
    "\n",
    "We then convolve x_image with the weight tensor, add the bias, apply the\n",
    "ReLU function, and finally max pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zero-padding and the stride of 1 we selected ensure that the output\n",
    "remains of the same size as the input image. \n",
    "\n",
    "#### Q2.2: What size is the patch ? How many lines/columns of zero-padding are there ? What would be the size of the output image if there was no padding ?\n",
    "\n",
    "#### Q2.3: What is the dimension of this layer ? What would it be if we did not do weight sharing ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Convolutional Layer\n",
    "\n",
    "In order to build a deep network, we stack several layers of this type. The\n",
    "second layer will have 64 features for each 5x5 patch.\n",
    "#### Q2.4: Code the second convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#answer\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Densely Connected Layer\n",
    "\n",
    "Now that the image size has been reduced to 7x7, we add a fully-connected layer with 1024 neurons to allow processing on the entire image. We reshape the tensor from the pooling layer into a batch of vectors, multiply by a weight matrix, add a bias, and apply a ReLU.\n",
    " \n",
    "#### Q2.5: Code the densely connected layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#answer\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add a softmax layer, just like for the one layer softmax \n",
    "regression above.\n",
    "\n",
    "#### Q2.6: code the softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.16\n",
      "step 100, training accuracy 0.82\n",
      "step 200, training accuracy 0.9\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 1\n",
      "step 500, training accuracy 0.92\n",
      "step 600, training accuracy 0.98\n",
      "step 700, training accuracy 0.94\n",
      "step 800, training accuracy 0.94\n",
      "step 900, training accuracy 1\n",
      "step 1000, training accuracy 0.98\n",
      "step 1100, training accuracy 1\n",
      "step 1200, training accuracy 0.98\n",
      "step 1300, training accuracy 1\n",
      "step 1400, training accuracy 1\n",
      "step 1500, training accuracy 0.96\n",
      "step 1600, training accuracy 0.98\n",
      "step 1700, training accuracy 1\n",
      "step 1800, training accuracy 0.98\n",
      "step 1900, training accuracy 0.94\n",
      "step 2000, training accuracy 0.98\n",
      "step 2100, training accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv=tf.nn.softmax(tf.matmul(h_fc1, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv), reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess.run(tf.initialize_all_variables())\n",
    "for i in range(2200):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1]})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2.7: How much observations are used at each step ? How much are used\n",
    "in the loop ?\n",
    "The classifier can be trained longer and it will still improve the performance:\n",
    "with 20000 iterations the accuracy is 0.992"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-962aa0ebe854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n\u001b[0m\u001b[1;32m      2\u001b[0m     x: mnist.test.images, y_: mnist.test.labels}))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "    x: mnist.test.images, y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.7: Take a look at some misclassified digits. Look at the softmax output. What do you think of the performance of the algorithm? Are you better ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correct, softmax=sess.run([correct_prediction,y_conv],feed_dict={\n",
    "    x: mnist.test.images[range(1000),], y_: mnist.test.labels[range(1000),]})\n",
    "\n",
    "np.where(correct==False)\n",
    "plt.matshow(np.reshape(mnist.test.images[247,],[28,28]))\n",
    "mnist.test.labels[247,]\n",
    "softmax[247,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.8: Vizualize all of the 32 filters of the first hidden layer in a single figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(1,33):\n",
    "    plt.subplot(8,4,i)\n",
    "    plt.imshow(0.2+sess.run(W_conv1)[:,:,0,i-1], cmap=plt.cm.BuPu_r)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.9: What is overfitting ? What ways do we have to limit overfitting for neural networks ? What is an additional advantage of drop-out ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2.10: recode the training step with a drop-out of 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#answer\n",
    "for i in range(3000):\n",
    "  batch = mnist.train.next_batch(50)\n",
    "  if i%100 == 0:\n",
    "    train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "    print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "  train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "close session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go further :\n",
    "Mnist is a baby problem compared to real life image recognition problem. What is ImageNet ? What are the best performances obtained on it and by what architecture ?\n",
    "You can also read this : http://karpathy.github.io/2014/09/02/what-i-learned-from-competing-against-a-convnet-on-imagenet/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
